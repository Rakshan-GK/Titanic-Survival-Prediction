# -*- coding: utf-8 -*-
"""titanic_survival_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gFfzZr-SjIhIXH_4MaKNUU3Ao3eGI3FX

# Titanic Survival Prediction
Project start date: YYYY-MM-DD  
Goal: Predict survival using classic Titanic dataset. This notebook documents data exploration, preprocessing, modeling, evaluation, and conclusions.
"""

!pip install -q pandas numpy matplotlib seaborn scikit-learn
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split
print("Setup OK")

df = pd.read_csv('train.csv')
df.head()

df.info()
df.isnull().sum()

"""## 2. Exploratory Data Analysis (EDA)
Investigate distributions, correlations and missing values to guide preprocessing.

"""

sns.countplot(x='Survived', data=df)
plt.title('Survival Count'); plt.show()

sns.barplot(x='Sex', y='Survived', data=df)
plt.title('Survival by Sex'); plt.show()

sns.barplot(x='Pclass', y='Survived', data=df)
plt.title('Survival by Pclass'); plt.show()

sns.boxplot(x='Survived', y='Age', data=df)
plt.title('Age vs Survived'); plt.show()

sns.heatmap(df.isnull(), cbar=False)
plt.title('Missing Data Map'); plt.show()

"""## 3. Preprocessing & Feature Engineering
Plan: fill Age with median, fill Embarked with mode, drop Cabin/Ticket/Name, create FamilySize and IsAlone, encode Sex and Embarked.

"""

# Step 3: Data Preprocessing (Fixed for pandas 3.0+)
df_processed = df.copy()  # always work on a copy to avoid SettingWithCopyWarning

# Handle missing values safely (no inplace=True)
df_processed['Age'] = df_processed['Age'].fillna(df_processed['Age'].median())
df_processed['Embarked'] = df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0])

# Drop irrelevant columns
df_processed = df_processed.drop(['Cabin', 'Ticket', 'Name'], axis=1)

# Encode categorical variables
df_processed['Sex'] = df_processed['Sex'].map({'male': 0, 'female': 1})
df_processed = pd.get_dummies(df_processed, columns=['Embarked'], drop_first=True)

df_processed.head()

"""## 4. Modeling — baseline
We'll use an 80/20 train/test split and train a Logistic Regression as baseline.

"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

X = df_processed.drop('Survived', axis=1)
y = df_processed['Survived']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model_lr = LogisticRegression(max_iter=1000)
model_lr.fit(X_train, y_train)
y_pred = model_lr.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d'); plt.show()

"""Feature Scaling using standard scaler."""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""## 5. Model comparison
Train Random Forest, Decision Tree, KNN and compare to Logistic Regression.

"""

# Step 5: Model Building and Comparison

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=200),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5)
}

results = {}

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc
    print(f"\n{name} Results:")
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

# Compare all models
print("\nModel Comparison Summary:")
for name, acc in results.items():
    print(f"{name}: {acc:.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
plt.barh(list(results.keys()), list(results.values()))
plt.xlabel("Accuracy")
plt.title("Model Comparison on Titanic Dataset")
plt.show()

"""## 6. Conclusion
- Best model: RandomForest (accuracy = 0.8380)

In this mini-project, we developed and compared multiple machine learning models to predict passenger survival on the **Titanic dataset**. The goal was to explore different classification algorithms, evaluate their performance, and understand the impact of preprocessing and feature engineering on model accuracy.

After cleaning and preprocessing the dataset — handling missing values, encoding categorical features, and standardizing numerical data — we trained and evaluated four models:

| Model                         | Type             | Approx. Accuracy | Key Traits                                           |
| ----------------------------- | ---------------- | ---------------- | ---------------------------------------------------- |
| **Logistic Regression**       | Linear           | ~79–81%          | Fast, interpretable, works well on scaled data       |
| **Decision Tree**             | Tree-based       | ~80–82%          | Simple, interpretable, prone to overfitting          |
| **Random Forest**             | Ensemble (Trees) | ~83–85%          | Best performance, robust against overfitting         |
| **K-Nearest Neighbors (KNN)** | Instance-based   | ~77–80%          | Simple, non-parametric, sensitive to feature scaling |

Among all models, the **Random Forest Classifier** achieved the **highest accuracy**, confirming that ensemble methods often outperform individual models on structured tabular data.

However, the differences between models were not extreme, showing that proper preprocessing and feature selection are as crucial as the model choice itself.

**Key Takeaways:**

* Data preprocessing (especially handling missing values and encoding) is essential for robust model performance.
* Ensemble methods like Random Forest provide strong baselines for structured datasets.
* Simpler models such as Logistic Regression can achieve competitive results when features are scaled properly.
* Model comparison helps in understanding trade-offs between interpretability, speed, and accuracy.
"""

